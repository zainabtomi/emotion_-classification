from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# ุชุญููู ุงููููุฐุฌ ูุงูุชููู
tokenizer = AutoTokenizer.from_pretrained("aubmindlab/bert-base-arabertv02")
model = AutoModelForSequenceClassification.from_pretrained("./arabert_emotion_model_phase1_saher_sarcasm")

# ุชุณููุงุช ุงููุฆุงุช ุญุณุจ ุงูุชุฏุฑูุจ
labels = ['Admiration', 'Anger', 'Fear', 'Happiness', 'Hope', 'Love', 'Oppressed Sorrow', 'Sarcasm', 'Yearning', 'other']

sentences = [
    "ูู ูู ูุฏูุดู ุฐูู ุงููุงุชุจุ ูุฌุนู ุงูุญุฑูู ุชุฑูุต ุนูู ุงููุฑู!",
    "ุชุตููู ุงูููุงู ูุนูุณ ุฐูููุง ุฑููุนูุง ูุง ููุฎุทุฆู ุงููุธุฑ.",
    "ุทุฑููุฉ ุดุฑุญู ุจุณูุทุฉุ ุนุจูุฑูุฉุ ูุชูุงูุณ ููู ุงููุงุฑุฆ ูุจุงุดุฑุฉ.",
    "ุฃุฏุงุก ุงููุฑูู ูุงู ููุณุฌููุง ุจุทุฑููุฉ ุชูุซูุฑ ุงูุฅุนุฌุงุจ.",
    "ูููุงุชูุง ูุงูุช ูุงูุณุญุฑุ ุชุฏุฎู ุงูููุจ ุฏูู ุงุณุชุฆุฐุงู.",
    "ูุง ุณูุงู ุนูู ุงูุฎุฏูุฉ ุงูููุชุงุฒุฉุ ุงุณุชููุช ุจุณ ุณุงุนุชูู ุจุฏูู ูุง ูุฑุฏ ุนููู ุฃุญุฏ!",
    "ุฃููุฏุ ูุฃูู ุทุจุนูุง ูู ูุฑุงุฑ ุญูููู ูุฏูู ุฑุงุญุชูุง ูุณุนุงุฏุชูุง.",
    "ูุง ุดุงุก ุงููู ุนูููุ ุนุจูุฑู ูุฏุฑุฌุฉ ุฃูู ูุณู ููู ูุญู ูุณุฃูุฉ ุฌูุน ุจุณูุทุฉ.",
    "ูู ุดูุก ูุงู ูุซุงูููุงุ ูููุง ุฃูู ูุดู ูุดููุง ุฐุฑูุนูุง!",
    "ุงููุช ูุงู ุณุฑูุน ุฌุฏูุงุ ุจุณ ุฃุฎุฐ ุณุงุนุฉ ุนุดุงู ููุชุญ ุตูุญุฉ ุฌูุฌู!"
]


# ุชุญููู ูู ุฌููุฉ
for text in sentences:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    max_prob, idx = torch.max(probs, dim=1)
    
    print("๐ ุงูุฌููุฉ:", text)
    print("๐ ุงูุชุตููู:", labels[idx.item()])
    print("๐ ุงููุณุจุฉ:", f"{max_prob.item()*100:.2f}%")
    print("-" * 40)

